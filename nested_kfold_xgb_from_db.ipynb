{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "bucket = 'baby-data'\n",
    "\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker.predictor import csv_serializer \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt  \n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "s3 = boto3.client('s3') \n",
    "\n",
    "pred_data = pd.DataFrame(columns=['actual', 'predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config # this is a file on my local computer that has my database login information\n",
    "db_engine = create_engine('mysql+pymysql://{0}:{1}@{2}:{3}/{4}'.format(config.login['username'], config.login['password'], config.login['host'], '3306', config.login['database']))\n",
    "connection = db_engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query data from database\n",
    "query = (\"Select Raw.isCSGM, Raw.recording_id, Generated.* \"\n",
    "         \"FROM Accelerometer_Generated Generated \"\n",
    "         \"INNER JOIN Accelerometer_Raw Raw \"\n",
    "         \"ON Raw.id = Generated.raw_id \"\n",
    "         \"ORDER BY Raw.timestamp\")\n",
    "data = pd.read_sql(query, connection)\n",
    "data.drop(['id', 'raw_id', 'left_arm_x_calibrated', 'left_arm_y_calibrated','left_arm_z_calibrated',\n",
    "            'right_arm_x_calibrated', 'right_arm_y_calibrated','right_arm_z_calibrated',\n",
    "            'left_leg_x_calibrated', 'left_leg_y_calibrated','left_leg_z_calibrated',\n",
    "            'right_leg_x_calibrated', 'right_leg_y_calibrated','right_leg_z_calibrated'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_id_list = data.recording_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = pd.read_csv('./pred_data.csv')\n",
    "\n",
    "for recording_id in recording_id_list:\n",
    "    # hold out one baby's data for testing\n",
    "    test_data = data.loc[data['recording_id'] == recording_id]\n",
    "    test_data = test_data.drop(['recording_id'], axis=1)\n",
    "    test_data = test_data.reset_index(drop=True)\n",
    "    \n",
    "    # separate the rest of the data into training and validation\n",
    "    train_data = pd.DataFrame(columns=data.columns)\n",
    "    validation_data = pd.DataFrame(columns=data.columns)\n",
    "    \n",
    "    # we want 70% of each baby's data in training and 30% of each baby's data in validation\n",
    "    for inner_recording_id in recording_id_list:\n",
    "        # make sure we aren't using the test data\n",
    "        if recording_id != inner_recording_id:\n",
    "            innerBabyData = data.loc[data['recording_id'] == recording_id]\n",
    "            innerBabyData = innerBabyData.reset_index(drop=True)\n",
    "            train, validation = np.split(innerBabyData, [int(0.7*len(innerBabyData))])    \n",
    "            train_data = train_data.append(train)\n",
    "            validation_data = validation_data.append(validation)        \n",
    "            \n",
    "    validation_data = validation_data.drop(['recording_id'], axis=1)\n",
    "    train_data = train_data.drop(['recording_id'], axis=1)\n",
    "    \n",
    "    train_data.to_csv('train.csv', index=False, header=False)\n",
    "    validation_data.to_csv('validation.csv', index=False, header=False)\n",
    "\n",
    "    # copy the file to S3\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object('train/train.csv').upload_file('train.csv')\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object('validation/validation.csv').upload_file('validation.csv')\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object('test/test.csv').upload_file('test.csv')\n",
    "\n",
    "    container = get_image_uri(boto3.Session().region_name, 'xgboost')\n",
    "\n",
    "    s3_input_train = sagemaker.s3_input(s3_data = 's3://{}/train'.format(bucket), content_type = 'csv')\n",
    "    s3_input_validation = sagemaker.s3_input(s3_data = 's3://{}/validation'.format(bucket), content_type = 'csv')\n",
    "\n",
    "    # train\n",
    "    sess = sagemaker.Session()\n",
    "\n",
    "    xgb = sagemaker.estimator.Estimator(container,\n",
    "                                       role,\n",
    "                                       train_instance_count=1,\n",
    "                                       train_instance_type='ml.m4.xlarge',\n",
    "                                       output_path='s3://{}/output'.format(bucket),\n",
    "                                       sagemaker_session=sess)\n",
    "    xgb.set_hyperparameters(objective='binary:logistic', \n",
    "                            eval_metric='error',\n",
    "                            alpha=1.5,\n",
    "                            eta=.05,\n",
    "                            max_depth=8,\n",
    "                            min_child_weight=3.7,\n",
    "                            num_round=100)\n",
    "\n",
    "    xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})\n",
    "    \n",
    "    # evaluate model\n",
    "    xgb_predictor = xgb.deploy(initial_instance_count=1,\n",
    "                               instance_type='ml.m4.xlarge')\n",
    "\n",
    "    xgb_predictor.content_type = 'text/csv'\n",
    "    xgb_predictor.serializer = csv_serializer\n",
    "    xgb_predictor.deserializer = None\n",
    "\n",
    "    def predict(data, rows=500):\n",
    "        split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "        predictions = ''\n",
    "        for array in split_array:\n",
    "            predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "        return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "    predictions = predict(test_data.as_matrix()[:, 1:])\n",
    "    \n",
    "    # concat actual data and prediction\n",
    "    predictionDF = pd.DataFrame(data=predictions)\n",
    "    addData = pd.concat([test_data['isCSGM'], predictionDF], axis=1, ignore_index=True)\n",
    "    addData = addData.rename(columns={0: \"actual\", 1: \"predicted\"})\n",
    "    \n",
    "    # add to pred_data\n",
    "    pred_data = pred_data.append(addData)\n",
    "    \n",
    "    # delete endpoint\n",
    "    sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
    "    \n",
    "    print('finished: ' + recording_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pred_data to notebook\n",
    "pred_data.to_csv('pred_data.csv', index=False, header=True)\n",
    "# boto3.Session().resource('s3').Bucket(bucket).Object('eval/pred_data.csv').upload_file('pred_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate predictions from all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "pd.crosstab(index=pred_data['actual'], columns=pred_data['predicted'].round(0), rownames=['actuals'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC Score\n",
    "print(\"Validation AUC\", roc_auc_score(list(pred_data['actual']), list(pred_data['predicted'])))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(list(pred_data['actual']), list(pred_data['predicted']))\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % (roc_auc))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "print(plt.figure())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
